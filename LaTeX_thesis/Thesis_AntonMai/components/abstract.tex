% Abstract for the TUM report document
% Included by MAIN.TEX


\clearemptydoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Abstract}





\vspace*{2cm}
\begin{center}
{\Large \bf Abstract}
\end{center}
\vspace{1cm}

%An abstracts abstracts the thesis!

Robotic Arms are used in many fields due to their high accuracy. A robotic arm has the advantage of being able to solve the same tasks like a human arm because of its similar structure, and being able to work repetitively and independently of any human. Setting up the task of a robotic arm requires the engineer to plan a path for solving the task. Using an approach with reinforcement learning to make the robotic arm learn the path independently has not been feasible due to the sparse rewards of robotic arm tasks. A recently successful method of using Reinforcement Learning is the concept of Hindsight Experience Replay. 

\vspace{0.5cm}

This thesis extends the difficulty of existing tasks to two new tasks and examines the performance of Hindsight Experience Replay on these tasks. 
In the first experiment the robotic arm has to move a ball towards a point that is far outside of its reach, similar to golf.
In the second experiment the task is to toss a ball into a box that is also outside of its reach, similar to basketball.

\vspace{0.5cm}

Results show that vanilla Hindsight Experience Replay performs poorly on these tasks. Further research with improvements to Hindsight Experience Replay, like Hindsight Goal Generation and Energy-Based Hindsight Experience Prioritization is required make further progress on solving these tasks.


